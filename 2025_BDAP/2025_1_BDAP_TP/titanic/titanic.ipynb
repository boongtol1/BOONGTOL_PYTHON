{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b1f284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_14224/3248462934.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/opt/miniconda3/envs/VDLP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-30 19:59:57.523326: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-05-30 19:59:57.523359: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 96.00 GB\n",
      "2025-05-30 19:59:57.523364: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 36.00 GB\n",
      "2025-05-30 19:59:57.523382: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-30 19:59:57.523397: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 19:59:58.174591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.4622 - loss: 0.8758 - val_accuracy: 0.6238 - val_loss: 0.7384\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6283 - loss: 0.7551 - val_accuracy: 0.7000 - val_loss: 0.6402\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7030 - loss: 0.6310 - val_accuracy: 0.7286 - val_loss: 0.5837\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7131 - loss: 0.5993 - val_accuracy: 0.7429 - val_loss: 0.5433\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7281 - loss: 0.5531 - val_accuracy: 0.7619 - val_loss: 0.5140\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7375 - loss: 0.5388 - val_accuracy: 0.8000 - val_loss: 0.4881\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7400 - loss: 0.5214 - val_accuracy: 0.8143 - val_loss: 0.4674\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7807 - loss: 0.4998 - val_accuracy: 0.8429 - val_loss: 0.4488\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8152 - loss: 0.4608 - val_accuracy: 0.8714 - val_loss: 0.4351\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8109 - loss: 0.4675 - val_accuracy: 0.8762 - val_loss: 0.4244\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8224 - loss: 0.4390 - val_accuracy: 0.8667 - val_loss: 0.4132\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.4414 - val_accuracy: 0.8714 - val_loss: 0.4044\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8260 - loss: 0.4377 - val_accuracy: 0.8667 - val_loss: 0.3963\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8322 - loss: 0.4110 - val_accuracy: 0.8762 - val_loss: 0.3904\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8395 - loss: 0.3997 - val_accuracy: 0.8762 - val_loss: 0.3840\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8238 - loss: 0.4669 - val_accuracy: 0.8762 - val_loss: 0.3822\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8378 - loss: 0.4296 - val_accuracy: 0.8714 - val_loss: 0.3813\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8367 - loss: 0.4094 - val_accuracy: 0.8714 - val_loss: 0.3787\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8609 - loss: 0.3906 - val_accuracy: 0.8714 - val_loss: 0.3740\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8282 - loss: 0.4328 - val_accuracy: 0.8714 - val_loss: 0.3732\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8426 - loss: 0.3841 - val_accuracy: 0.8714 - val_loss: 0.3698\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8269 - loss: 0.4372 - val_accuracy: 0.8714 - val_loss: 0.3708\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8429 - loss: 0.4000 - val_accuracy: 0.8714 - val_loss: 0.3717\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8283 - loss: 0.4408 - val_accuracy: 0.8667 - val_loss: 0.3730\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8353 - loss: 0.4196 - val_accuracy: 0.8714 - val_loss: 0.3722\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.4046 - val_accuracy: 0.8714 - val_loss: 0.3691\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8368 - loss: 0.4265 - val_accuracy: 0.8714 - val_loss: 0.3680\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8714 - loss: 0.3523 - val_accuracy: 0.8714 - val_loss: 0.3652\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8249 - loss: 0.4435 - val_accuracy: 0.8667 - val_loss: 0.3688\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8583 - loss: 0.3670 - val_accuracy: 0.8714 - val_loss: 0.3657\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8207 - loss: 0.4272 - val_accuracy: 0.8714 - val_loss: 0.3635\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8295 - loss: 0.3989 - val_accuracy: 0.8714 - val_loss: 0.3640\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8359 - loss: 0.4203 - val_accuracy: 0.8762 - val_loss: 0.3627\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8794 - loss: 0.3450 - val_accuracy: 0.8714 - val_loss: 0.3637\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8653 - loss: 0.3909 - val_accuracy: 0.8714 - val_loss: 0.3657\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8787 - loss: 0.3415 - val_accuracy: 0.8714 - val_loss: 0.3654\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8436 - loss: 0.3801 - val_accuracy: 0.8667 - val_loss: 0.3677\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8570 - loss: 0.3652 - val_accuracy: 0.8714 - val_loss: 0.3653\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8416 - loss: 0.4088 - val_accuracy: 0.8714 - val_loss: 0.3651\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.4145 - val_accuracy: 0.8714 - val_loss: 0.3652\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8424 - loss: 0.3980 - val_accuracy: 0.8762 - val_loss: 0.3646\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8622 - loss: 0.3786 - val_accuracy: 0.8762 - val_loss: 0.3641\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8659 - loss: 0.3697 - val_accuracy: 0.8762 - val_loss: 0.3631\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8546 - loss: 0.3914 - val_accuracy: 0.8762 - val_loss: 0.3649\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8377 - loss: 0.4130 - val_accuracy: 0.8714 - val_loss: 0.3641\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8387 - loss: 0.4119 - val_accuracy: 0.8714 - val_loss: 0.3627\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8594 - loss: 0.3840 - val_accuracy: 0.8714 - val_loss: 0.3643\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8588 - loss: 0.3772 - val_accuracy: 0.8714 - val_loss: 0.3637\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8556 - loss: 0.3907 - val_accuracy: 0.8714 - val_loss: 0.3655\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8427 - loss: 0.4092 - val_accuracy: 0.8762 - val_loss: 0.3656\n",
      "[TensorFlow] Test Accuracy: 0.8473\n"
     ]
    }
   ],
   "source": [
    "# titanic_tf_simple.py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"titanic1309.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ ì‚¬ìš©í•  ì—´ ì„ íƒ\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "# 3ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: í‰ê· ìœ¼ë¡œ, ë²”ì£¼í˜•: ê°€ì¥ ë§ì€ ê°’ìœ¼ë¡œ)\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ ë²”ì£¼í˜•ì„ ìˆ«ìë¡œ ë³€í™˜ (ì›-í•« ì¸ì½”ë”©)\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# 5ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (í‰ê· =0, í‘œì¤€í¸ì°¨=1)\n",
    "scaler = StandardScaler()\n",
    "X[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.fit_transform(X[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']])\n",
    "\n",
    "# 6ï¸âƒ£ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7ï¸âƒ£ TensorFlow ëª¨ë¸\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 8ï¸âƒ£ í…ŒìŠ¤íŠ¸ì…‹ ì •í™•ë„ í‰ê°€\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"[TensorFlow] Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3064872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae8609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/749973377.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/VDLP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-06-01 11:03:14.146957: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-06-01 11:03:14.146997: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 96.00 GB\n",
      "2025-06-01 11:03:14.147002: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 36.00 GB\n",
      "2025-06-01 11:03:14.147155: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-06-01 11:03:14.147167: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-06-01 11:03:14.521727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6999 - loss: 0.6038 - val_accuracy: 0.7810 - val_loss: 0.5012\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7187 - loss: 0.5590 - val_accuracy: 0.8286 - val_loss: 0.4718\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7403 - loss: 0.5412 - val_accuracy: 0.8381 - val_loss: 0.4560\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7449 - loss: 0.5484 - val_accuracy: 0.8571 - val_loss: 0.4453\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7725 - loss: 0.5490 - val_accuracy: 0.8619 - val_loss: 0.4306\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7792 - loss: 0.4889 - val_accuracy: 0.8762 - val_loss: 0.4187\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8069 - loss: 0.4843 - val_accuracy: 0.8619 - val_loss: 0.4119\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7806 - loss: 0.4980 - val_accuracy: 0.8714 - val_loss: 0.4079\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8134 - loss: 0.4649 - val_accuracy: 0.8810 - val_loss: 0.3989\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8155 - loss: 0.4560 - val_accuracy: 0.8762 - val_loss: 0.3948\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8136 - loss: 0.4454 - val_accuracy: 0.8714 - val_loss: 0.3868\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8058 - loss: 0.4718 - val_accuracy: 0.8762 - val_loss: 0.3841\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8252 - loss: 0.4398 - val_accuracy: 0.8714 - val_loss: 0.3831\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8213 - loss: 0.4124 - val_accuracy: 0.8762 - val_loss: 0.3793\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8145 - loss: 0.4471 - val_accuracy: 0.8714 - val_loss: 0.3804\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.4067 - val_accuracy: 0.8762 - val_loss: 0.3772\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8100 - loss: 0.4508 - val_accuracy: 0.8762 - val_loss: 0.3752\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8158 - loss: 0.4271 - val_accuracy: 0.8762 - val_loss: 0.3746\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8269 - loss: 0.4063 - val_accuracy: 0.8714 - val_loss: 0.3732\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8238 - loss: 0.4225 - val_accuracy: 0.8762 - val_loss: 0.3711\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.4044 - val_accuracy: 0.8762 - val_loss: 0.3708\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8370 - loss: 0.4177 - val_accuracy: 0.8762 - val_loss: 0.3700\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7963 - loss: 0.4572 - val_accuracy: 0.8857 - val_loss: 0.3714\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8348 - loss: 0.3936 - val_accuracy: 0.8810 - val_loss: 0.3713\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8136 - loss: 0.4238 - val_accuracy: 0.8810 - val_loss: 0.3724\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.4004 - val_accuracy: 0.8810 - val_loss: 0.3703\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.4221 - val_accuracy: 0.8810 - val_loss: 0.3727\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.4090 - val_accuracy: 0.8810 - val_loss: 0.3720\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8535 - loss: 0.3675 - val_accuracy: 0.8762 - val_loss: 0.3708\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8361 - loss: 0.4032 - val_accuracy: 0.8762 - val_loss: 0.3714\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8263 - loss: 0.4052 - val_accuracy: 0.8762 - val_loss: 0.3688\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8443 - loss: 0.4001 - val_accuracy: 0.8762 - val_loss: 0.3700\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8179 - loss: 0.4321 - val_accuracy: 0.8714 - val_loss: 0.3684\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8321 - loss: 0.4136 - val_accuracy: 0.8810 - val_loss: 0.3679\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8398 - loss: 0.4087 - val_accuracy: 0.8810 - val_loss: 0.3701\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8293 - loss: 0.4282 - val_accuracy: 0.8810 - val_loss: 0.3686\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8410 - loss: 0.4269 - val_accuracy: 0.8810 - val_loss: 0.3683\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8331 - loss: 0.4206 - val_accuracy: 0.8857 - val_loss: 0.3698\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.4262 - val_accuracy: 0.8762 - val_loss: 0.3720\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8281 - loss: 0.4317 - val_accuracy: 0.8762 - val_loss: 0.3716\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8376 - loss: 0.4354 - val_accuracy: 0.8762 - val_loss: 0.3714\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8583 - loss: 0.3769 - val_accuracy: 0.8714 - val_loss: 0.3718\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8642 - loss: 0.3751 - val_accuracy: 0.8857 - val_loss: 0.3712\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8336 - loss: 0.4114 - val_accuracy: 0.8857 - val_loss: 0.3715\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8267 - loss: 0.4119 - val_accuracy: 0.8810 - val_loss: 0.3722\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8410 - loss: 0.3930 - val_accuracy: 0.8810 - val_loss: 0.3735\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8495 - loss: 0.3949 - val_accuracy: 0.8810 - val_loss: 0.3735\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8209 - loss: 0.4323 - val_accuracy: 0.8857 - val_loss: 0.3749\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8262 - loss: 0.4203 - val_accuracy: 0.8810 - val_loss: 0.3742\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8132 - loss: 0.4463 - val_accuracy: 0.8810 - val_loss: 0.3730\n",
      "[TensorFlow] Test Accuracy: 0.8435\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      "ğŸ¯ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥  (ì• 10ê°œ ìƒ˜í”Œ):\n",
      "ìƒ˜í”Œ 1 â†’ ìƒì¡´ í™•ë¥ : 0.9403\n",
      "ìƒ˜í”Œ 2 â†’ ìƒì¡´ í™•ë¥ : 0.0479\n",
      "ìƒ˜í”Œ 3 â†’ ìƒì¡´ í™•ë¥ : 0.4011\n",
      "ìƒ˜í”Œ 4 â†’ ìƒì¡´ í™•ë¥ : 0.2822\n",
      "ìƒ˜í”Œ 5 â†’ ìƒì¡´ í™•ë¥ : 0.3133\n",
      "ìƒ˜í”Œ 6 â†’ ìƒì¡´ í™•ë¥ : 0.8664\n",
      "ìƒ˜í”Œ 7 â†’ ìƒì¡´ í™•ë¥ : 0.2642\n",
      "ìƒ˜í”Œ 8 â†’ ìƒì¡´ í™•ë¥ : 0.0818\n",
      "ìƒ˜í”Œ 9 â†’ ìƒì¡´ í™•ë¥ : 0.6787\n",
      "ìƒ˜í”Œ 10 â†’ ìƒì¡´ í™•ë¥ : 0.0689\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"titanic1309.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ ì‚¬ìš©í•  ì—´ ì„ íƒ\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "# 3ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: í‰ê· ìœ¼ë¡œ, ë²”ì£¼í˜•: ê°€ì¥ ë§ì€ ê°’ìœ¼ë¡œ)\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ ë²”ì£¼í˜•ì„ ìˆ«ìë¡œ ë³€í™˜ (ì›-í•« ì¸ì½”ë”©)\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# 5ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (í‰ê· =0, í‘œì¤€í¸ì°¨=1)\n",
    "scaler = StandardScaler()\n",
    "X[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.fit_transform(X[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']])\n",
    "\n",
    "# 6ï¸âƒ£ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7ï¸âƒ£ TensorFlow ëª¨ë¸\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 8ï¸âƒ£ í…ŒìŠ¤íŠ¸ì…‹ ì •í™•ë„ í‰ê°€\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"[TensorFlow] Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 9ï¸âƒ£ í…ŒìŠ¤íŠ¸ì…‹ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥  ì¶œë ¥\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# 0~1 ì‚¬ì´ì˜ ìƒì¡´ í™•ë¥  ì¶œë ¥ (ì•ë¶€ë¶„ë§Œ ì¼ë¶€ í™•ì¸)\n",
    "print(\"\\nğŸ¯ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥  (ì• 10ê°œ ìƒ˜í”Œ):\")\n",
    "for idx, prob in enumerate(y_pred_probs[:10]):\n",
    "    print(f\"ìƒ˜í”Œ {idx+1} â†’ ìƒì¡´ í™•ë¥ : {prob[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e3c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/796972916.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/opt/miniconda3/envs/VDLP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6455 - loss: 0.6715 - val_accuracy: 0.7571 - val_loss: 0.5885\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6708 - loss: 0.6123 - val_accuracy: 0.7524 - val_loss: 0.5411\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6944 - loss: 0.5752 - val_accuracy: 0.7571 - val_loss: 0.5165\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7261 - loss: 0.5293 - val_accuracy: 0.7667 - val_loss: 0.5013\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7239 - loss: 0.5379 - val_accuracy: 0.7714 - val_loss: 0.4883\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7488 - loss: 0.5099 - val_accuracy: 0.7810 - val_loss: 0.4768\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7403 - loss: 0.5184 - val_accuracy: 0.7905 - val_loss: 0.4655\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7157 - loss: 0.5267 - val_accuracy: 0.8095 - val_loss: 0.4584\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7764 - loss: 0.5036 - val_accuracy: 0.8381 - val_loss: 0.4493\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7968 - loss: 0.4711 - val_accuracy: 0.8333 - val_loss: 0.4409\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7961 - loss: 0.4698 - val_accuracy: 0.8571 - val_loss: 0.4314\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7781 - loss: 0.4778 - val_accuracy: 0.8524 - val_loss: 0.4227\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8061 - loss: 0.4886 - val_accuracy: 0.8571 - val_loss: 0.4146\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8167 - loss: 0.4581 - val_accuracy: 0.8619 - val_loss: 0.4060\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8069 - loss: 0.4213 - val_accuracy: 0.8619 - val_loss: 0.4009\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8037 - loss: 0.4299 - val_accuracy: 0.8524 - val_loss: 0.3944\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.4062 - val_accuracy: 0.8571 - val_loss: 0.3916\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8486 - loss: 0.3901 - val_accuracy: 0.8571 - val_loss: 0.3870\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8392 - loss: 0.3984 - val_accuracy: 0.8571 - val_loss: 0.3844\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8343 - loss: 0.4174 - val_accuracy: 0.8571 - val_loss: 0.3842\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8379 - loss: 0.3752 - val_accuracy: 0.8571 - val_loss: 0.3808\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8378 - loss: 0.3984 - val_accuracy: 0.8571 - val_loss: 0.3780\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8318 - loss: 0.3832 - val_accuracy: 0.8667 - val_loss: 0.3762\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8432 - loss: 0.3963 - val_accuracy: 0.8667 - val_loss: 0.3770\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8347 - loss: 0.4240 - val_accuracy: 0.8667 - val_loss: 0.3772\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8508 - loss: 0.3908 - val_accuracy: 0.8667 - val_loss: 0.3744\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8386 - loss: 0.3870 - val_accuracy: 0.8667 - val_loss: 0.3733\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8278 - loss: 0.4319 - val_accuracy: 0.8667 - val_loss: 0.3726\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8585 - loss: 0.3781 - val_accuracy: 0.8667 - val_loss: 0.3712\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8330 - loss: 0.4079 - val_accuracy: 0.8667 - val_loss: 0.3713\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8580 - loss: 0.3673 - val_accuracy: 0.8667 - val_loss: 0.3715\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8504 - loss: 0.3851 - val_accuracy: 0.8667 - val_loss: 0.3699\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8619 - loss: 0.3735 - val_accuracy: 0.8667 - val_loss: 0.3713\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8706 - loss: 0.3384 - val_accuracy: 0.8667 - val_loss: 0.3711\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8066 - loss: 0.4132 - val_accuracy: 0.8667 - val_loss: 0.3719\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8308 - loss: 0.3916 - val_accuracy: 0.8667 - val_loss: 0.3728\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8474 - loss: 0.3858 - val_accuracy: 0.8667 - val_loss: 0.3705\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8568 - loss: 0.3867 - val_accuracy: 0.8667 - val_loss: 0.3687\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.4026 - val_accuracy: 0.8667 - val_loss: 0.3694\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8367 - loss: 0.3987 - val_accuracy: 0.8762 - val_loss: 0.3684\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8548 - loss: 0.3698 - val_accuracy: 0.8714 - val_loss: 0.3687\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8578 - loss: 0.3920 - val_accuracy: 0.8667 - val_loss: 0.3689\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7930 - loss: 0.4856 - val_accuracy: 0.8667 - val_loss: 0.3689\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8237 - loss: 0.4305 - val_accuracy: 0.8714 - val_loss: 0.3674\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8530 - loss: 0.3739 - val_accuracy: 0.8667 - val_loss: 0.3703\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8240 - loss: 0.4103 - val_accuracy: 0.8667 - val_loss: 0.3692\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8370 - loss: 0.3906 - val_accuracy: 0.8571 - val_loss: 0.3726\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8513 - loss: 0.3839 - val_accuracy: 0.8619 - val_loss: 0.3723\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.4111 - val_accuracy: 0.8714 - val_loss: 0.3687\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8331 - loss: 0.3981 - val_accuracy: 0.8714 - val_loss: 0.3701\n",
      "[TensorFlow] Test Accuracy: 0.8397\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      "ğŸ¯ í…ŒìŠ¤íŠ¸ì…‹ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥ :\n",
      "PassengerId: 951, Name: Chaudanson, Miss. Victorine, ìƒì¡´ í™•ë¥ : 0.9661\n",
      "PassengerId: 812, Name: Lester, Mr. James, ìƒì¡´ í™•ë¥ : 0.0538\n",
      "PassengerId: 476, Name: Clifford, Mr. George Quincy, ìƒì¡´ í™•ë¥ : 0.4435\n",
      "PassengerId: 1137, Name: Kenyon, Mr. Frederick R, ìƒì¡´ í™•ë¥ : 0.3089\n",
      "PassengerId: 138, Name: Futrelle, Mr. Jacques Heath, ìƒì¡´ í™•ë¥ : 0.3411\n",
      "PassengerId: 944, Name: Hocking, Miss. Ellen Nellie\"\", ìƒì¡´ í™•ë¥ : 0.8641\n",
      "PassengerId: 903, Name: Jones, Mr. Charles Cresson, ìƒì¡´ í™•ë¥ : 0.2911\n",
      "PassengerId: 754, Name: Jonkoff, Mr. Lalio, ìƒì¡´ í™•ë¥ : 0.0868\n",
      "PassengerId: 1302, Name: Naughton, Miss. Hannah, ìƒì¡´ í™•ë¥ : 0.7591\n",
      "PassengerId: 354, Name: Arnold-Franchi, Mr. Josef, ìƒì¡´ í™•ë¥ : 0.0709\n",
      "PassengerId: 1024, Name: Lefebre, Mrs. Frank (Frances), ìƒì¡´ í™•ë¥ : 0.5870\n",
      "PassengerId: 1230, Name: Denbury, Mr. Herbert, ìƒì¡´ í™•ë¥ : 0.2256\n",
      "PassengerId: 1241, Name: Walcroft, Miss. Nellie, ìƒì¡´ í™•ë¥ : 0.8755\n",
      "PassengerId: 28, Name: Fortune, Mr. Charles Alexander, ìƒì¡´ í™•ë¥ : 0.5159\n",
      "PassengerId: 4, Name: Futrelle, Mrs. Jacques Heath (Lily May Peel), ìƒì¡´ í™•ë¥ : 0.9451\n",
      "PassengerId: 565, Name: Meanwell, Miss. (Marion Ogden), ìƒì¡´ í™•ë¥ : 0.6974\n",
      "PassengerId: 161, Name: Cribb, Mr. John Hatfield, ìƒì¡´ í™•ë¥ : 0.0388\n",
      "PassengerId: 1161, Name: Pokrnic, Mr. Mate, ìƒì¡´ í™•ë¥ : 0.1056\n",
      "PassengerId: 667, Name: Butler, Mr. Reginald Fenton, ìƒì¡´ í™•ë¥ : 0.2147\n",
      "PassengerId: 830, Name: Stone, Mrs. George Nelson (Martha Evelyn), ìƒì¡´ í™•ë¥ : 0.8963\n",
      "PassengerId: 555, Name: Ohman, Miss. Velin, ìƒì¡´ í™•ë¥ : 0.7531\n",
      "PassengerId: 181, Name: Sage, Miss. Constance Gladys, ìƒì¡´ í™•ë¥ : 0.3361\n",
      "PassengerId: 1134, Name: Spedden, Mr. Frederic Oakley, ìƒì¡´ í™•ë¥ : 0.2389\n",
      "PassengerId: 329, Name: Goldsmith, Mrs. Frank John (Emily Alice Brown), ìƒì¡´ í™•ë¥ : 0.6272\n",
      "PassengerId: 1297, Name: Nourney, Mr. Alfred (Baron von Drachstedt\")\", ìƒì¡´ í™•ë¥ : 0.1866\n",
      "PassengerId: 933, Name: Franklin, Mr. Thomas Parham, ìƒì¡´ í™•ë¥ : 0.4222\n",
      "PassengerId: 1005, Name: Buckley, Miss. Katherine, ìƒì¡´ í™•ë¥ : 0.8252\n",
      "PassengerId: 436, Name: Carter, Miss. Lucile Polk, ìƒì¡´ í™•ë¥ : 0.9721\n",
      "PassengerId: 647, Name: Cor, Mr. Liudevit, ìƒì¡´ í™•ë¥ : 0.0988\n",
      "PassengerId: 1142, Name: West, Miss. Barbara J, ìƒì¡´ í™•ë¥ : 0.9303\n",
      "PassengerId: 153, Name: Meo, Mr. Alfonzo, ìƒì¡´ í™•ë¥ : 0.0290\n",
      "PassengerId: 246, Name: Minahan, Dr. William Edward, ìƒì¡´ í™•ë¥ : 0.3429\n",
      "PassengerId: 915, Name: Williams, Mr. Richard Norris II, ìƒì¡´ í™•ë¥ : 0.4082\n",
      "PassengerId: 1052, Name: Smyth, Miss. Julia, ìƒì¡´ í™•ë¥ : 0.7591\n",
      "PassengerId: 1073, Name: Compton, Mr. Alexander Taylor Jr, ìƒì¡´ í™•ë¥ : 0.2594\n",
      "PassengerId: 392, Name: Jansson, Mr. Carl Olof, ìƒì¡´ í™•ë¥ : 0.0926\n",
      "PassengerId: 1107, Name: Head, Mr. Christopher, ìƒì¡´ í™•ë¥ : 0.3338\n",
      "PassengerId: 1128, Name: Warren, Mr. Frank Manley, ìƒì¡´ í™•ë¥ : 0.1299\n",
      "PassengerId: 638, Name: Collyer, Mr. Harvey, ìƒì¡´ í™•ë¥ : 0.1440\n",
      "PassengerId: 567, Name: Stoytcheff, Mr. Ilia, ìƒì¡´ í™•ë¥ : 0.0988\n",
      "PassengerId: 516, Name: Walker, Mr. William Anderson, ìƒì¡´ í™•ë¥ : 0.2894\n",
      "PassengerId: 1251, Name: Lindell, Mrs. Edvard Bengtsson (Elin Gerda Persson), ìƒì¡´ í™•ë¥ : 0.6625\n",
      "PassengerId: 48, Name: O'Driscoll, Miss. Bridget, ìƒì¡´ í™•ë¥ : 0.7591\n",
      "PassengerId: 1307, Name: Saether, Mr. Simon Sivertsen, ìƒì¡´ í™•ë¥ : 0.0518\n",
      "PassengerId: 2, Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), ìƒì¡´ í™•ë¥ : 0.9201\n",
      "PassengerId: 1061, Name: Hellstrom, Miss. Hilda Maria, ìƒì¡´ í™•ë¥ : 0.7538\n",
      "PassengerId: 660, Name: Newell, Mr. Arthur Webster, ìƒì¡´ í™•ë¥ : 0.1613\n",
      "PassengerId: 643, Name: Skoog, Miss. Margit Elizabeth, ìƒì¡´ í™•ë¥ : 0.7464\n",
      "PassengerId: 378, Name: Widener, Mr. Harry Elkins, ìƒì¡´ í™•ë¥ : 0.4480\n",
      "PassengerId: 818, Name: Mallet, Mr. Albert, ìƒì¡´ í™•ë¥ : 0.1088\n",
      "PassengerId: 195, Name: Brown, Mrs. James Joseph (Margaret Tobin), ìƒì¡´ í™•ë¥ : 0.9058\n",
      "PassengerId: 129, Name: Peter, Miss. Anna, ìƒì¡´ í™•ë¥ : 0.5521\n",
      "PassengerId: 902, Name: Ilieff, Mr. Ylio, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 16, Name: Hewlett, Mrs. (Mary D Kingcome) , ìƒì¡´ í™•ë¥ : 0.7461\n",
      "PassengerId: 355, Name: Yousif, Mr. Wazli, ìƒì¡´ í™•ë¥ : 0.0494\n",
      "PassengerId: 104, Name: Johansson, Mr. Gustaf Joel, ìƒì¡´ í™•ë¥ : 0.0626\n",
      "PassengerId: 92, Name: Andreasson, Mr. Paul Edvin, ìƒì¡´ í™•ë¥ : 0.0956\n",
      "PassengerId: 582, Name: Thayer, Mrs. John Borland (Marian Longstreth Morris), ìƒì¡´ í™•ë¥ : 0.9174\n",
      "PassengerId: 1276, Name: Wheeler, Mr. Edwin Frederick\"\", ìƒì¡´ í™•ë¥ : 0.1868\n",
      "PassengerId: 604, Name: Torber, Mr. Ernst William, ìƒì¡´ í™•ë¥ : 0.0431\n",
      "PassengerId: 964, Name: Nieminen, Miss. Manta Josefina, ìƒì¡´ í™•ë¥ : 0.7039\n",
      "PassengerId: 1077, Name: Maybery, Mr. Frank Hubert, ìƒì¡´ í™•ë¥ : 0.1393\n",
      "PassengerId: 149, Name: Navratil, Mr. Michel (\"Louis M Hoffman\"), ìƒì¡´ í™•ë¥ : 0.1264\n",
      "PassengerId: 1062, Name: Lithman, Mr. Simon, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 544, Name: Beane, Mr. Edward, ìƒì¡´ í™•ë¥ : 0.1566\n",
      "PassengerId: 775, Name: Hocking, Mrs. Elizabeth (Eliza Needs), ìƒì¡´ í™•ë¥ : 0.6337\n",
      "PassengerId: 1141, Name: Khalil, Mrs. Betros (Zahie Maria\" Elias)\", ìƒì¡´ í™•ë¥ : 0.5788\n",
      "PassengerId: 699, Name: Thayer, Mr. John Borland, ìƒì¡´ í™•ë¥ : 0.2007\n",
      "PassengerId: 63, Name: Harris, Mr. Henry Birkhardt, ìƒì¡´ í™•ë¥ : 0.3015\n",
      "PassengerId: 605, Name: Homer, Mr. Harry (\"Mr E Haven\"), ìƒì¡´ í™•ë¥ : 0.2988\n",
      "PassengerId: 519, Name: Angle, Mrs. William A (Florence \"Mary\" Agnes Hughes), ìƒì¡´ í™•ë¥ : 0.8330\n",
      "PassengerId: 1139, Name: Drew, Mr. James Vivian, ìƒì¡´ í™•ë¥ : 0.1040\n",
      "PassengerId: 1171, Name: Oxenham, Mr. Percy Thomas, ìƒì¡´ í™•ë¥ : 0.2318\n",
      "PassengerId: 899, Name: Caldwell, Mr. Albert Francis, ìƒì¡´ í™•ë¥ : 0.1687\n",
      "PassengerId: 685, Name: Brown, Mr. Thomas William Solomon, ìƒì¡´ í™•ë¥ : 0.0588\n",
      "PassengerId: 398, Name: McKane, Mr. Peter David, ìƒì¡´ í™•ë¥ : 0.1191\n",
      "PassengerId: 1117, Name: Moubarek, Mrs. George (Omine Amenia\" Alexander)\", ìƒì¡´ í™•ë¥ : 0.5575\n",
      "PassengerId: 778, Name: Emanuel, Miss. Virginia Ethel, ìƒì¡´ í™•ë¥ : 0.8503\n",
      "PassengerId: 411, Name: Sdycoff, Mr. Todor, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 1224, Name: Thomas, Mr. Tannous, ìƒì¡´ í™•ë¥ : 0.0494\n",
      "PassengerId: 753, Name: Vande Velde, Mr. Johannes Joseph, ìƒì¡´ í™•ë¥ : 0.0627\n",
      "PassengerId: 204, Name: Youseff, Mr. Gerious, ìƒì¡´ í™•ë¥ : 0.0289\n",
      "PassengerId: 474, Name: Jerwan, Mrs. Amin S (Marie Marthe Thuillard), ìƒì¡´ í™•ë¥ : 0.8645\n",
      "PassengerId: 294, Name: Haas, Miss. Aloisia, ìƒì¡´ í™•ë¥ : 0.7403\n",
      "PassengerId: 24, Name: Sloper, Mr. William Thompson, ìƒì¡´ í™•ë¥ : 0.4462\n",
      "PassengerId: 50, Name: Arnold-Franchi, Mrs. Josef (Josefine Franchi), ìƒì¡´ í™•ë¥ : 0.7521\n",
      "PassengerId: 296, Name: Lewy, Mr. Ervin G, ìƒì¡´ í™•ë¥ : 0.3392\n",
      "PassengerId: 751, Name: Wells, Miss. Joan, ìƒì¡´ í™•ë¥ : 0.9310\n",
      "PassengerId: 677, Name: Sawyer, Mr. Frederick Charles, ìƒì¡´ í™•ë¥ : 0.0827\n",
      "PassengerId: 323, Name: Slayter, Miss. Hilda Mary, ìƒì¡´ í™•ë¥ : 0.9063\n",
      "PassengerId: 556, Name: Wright, Mr. George, ìƒì¡´ í™•ë¥ : 0.1888\n",
      "PassengerId: 828, Name: Mallet, Master. Andre, ìƒì¡´ í™•ë¥ : 0.2713\n",
      "PassengerId: 1047, Name: Duquemin, Mr. Joseph, ìƒì¡´ í™•ë¥ : 0.0839\n",
      "PassengerId: 135, Name: Sobey, Mr. Samuel James Hayden, ìƒì¡´ í™•ë¥ : 0.2147\n",
      "PassengerId: 774, Name: Elias, Mr. Dibo, ìƒì¡´ í™•ë¥ : 0.0494\n",
      "PassengerId: 486, Name: Lefebre, Miss. Jeannie, ìƒì¡´ í™•ë¥ : 0.5532\n",
      "PassengerId: 656, Name: Hickman, Mr. Leonard Mark, ìƒì¡´ í™•ë¥ : 0.1950\n",
      "PassengerId: 454, Name: Goldenberg, Mr. Samuel L, ìƒì¡´ í™•ë¥ : 0.2107\n",
      "PassengerId: 827, Name: Lam, Mr. Len, ìƒì¡´ í™•ë¥ : 0.0807\n",
      "PassengerId: 635, Name: Skoog, Miss. Mabel, ìƒì¡´ í™•ë¥ : 0.6964\n",
      "PassengerId: 702, Name: Silverthorne, Mr. Spencer Victor, ìƒì¡´ í™•ë¥ : 0.3783\n",
      "PassengerId: 924, Name: Dean, Mrs. Bertram (Eva Georgetta Light), ìƒì¡´ í™•ë¥ : 0.5777\n",
      "PassengerId: 402, Name: Adams, Mr. John, ìƒì¡´ í™•ë¥ : 0.0787\n",
      "PassengerId: 796, Name: Otter, Mr. Richard, ìƒì¡´ í™•ë¥ : 0.1424\n",
      "PassengerId: 490, Name: Coutts, Master. Eden Leslie \"Neville\", ìƒì¡´ í™•ë¥ : 0.1048\n",
      "PassengerId: 1007, Name: Chronopoulos, Mr. Demetrios, ìƒì¡´ í™•ë¥ : 0.0635\n",
      "PassengerId: 1189, Name: Samaan, Mr. Hanna, ìƒì¡´ í™•ë¥ : 0.0365\n",
      "PassengerId: 84, Name: Carrau, Mr. Francisco M, ìƒì¡´ í™•ë¥ : 0.4560\n",
      "PassengerId: 399, Name: Pain, Dr. Alfred, ìƒì¡´ í™•ë¥ : 0.2255\n",
      "PassengerId: 39, Name: Vander Planke, Miss. Augusta Maria, ìƒì¡´ í™•ë¥ : 0.7168\n",
      "PassengerId: 30, Name: Todoroff, Mr. Lalio, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 1113, Name: Reynolds, Mr. Harold J, ìƒì¡´ í™•ë¥ : 0.0927\n",
      "PassengerId: 253, Name: Stead, Mr. William Thomas, ìƒì¡´ í™•ë¥ : 0.1888\n",
      "PassengerId: 707, Name: Kelly, Mrs. Florence \"Fannie\", ìƒì¡´ í™•ë¥ : 0.8062\n",
      "PassengerId: 645, Name: Baclini, Miss. Eugenie, ìƒì¡´ í™•ë¥ : 0.7417\n",
      "PassengerId: 397, Name: Olsson, Miss. Elina, ìƒì¡´ í™•ë¥ : 0.6888\n",
      "PassengerId: 142, Name: Nysten, Miss. Anna Sofia, ìƒì¡´ í™•ë¥ : 0.7530\n",
      "PassengerId: 932, Name: Karun, Mr. Franz, ìƒì¡´ í™•ë¥ : 0.0324\n",
      "PassengerId: 1122, Name: Sweet, Mr. George Frederick, ìƒì¡´ í™•ë¥ : 0.3258\n",
      "PassengerId: 805, Name: Hedman, Mr. Oskar Arvid, ìƒì¡´ í™•ë¥ : 0.0759\n",
      "PassengerId: 577, Name: Garside, Miss. Ethel, ìƒì¡´ í™•ë¥ : 0.8601\n",
      "PassengerId: 919, Name: Daher, Mr. Shedid, ìƒì¡´ í™•ë¥ : 0.0633\n",
      "PassengerId: 1060, Name: Cassebeer, Mrs. Henry Arthur Jr (Eleanor Genevieve Fosdick), ìƒì¡´ í™•ë¥ : 0.9408\n",
      "PassengerId: 561, Name: Morrow, Mr. Thomas Rowan, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 1222, Name: Davies, Mrs. John Morgan (Elizabeth Agnes Mary White) , ìƒì¡´ í™•ë¥ : 0.7552\n",
      "PassengerId: 317, Name: Kantor, Mrs. Sinai (Miriam Sternin), ìƒì¡´ í™•ë¥ : 0.8844\n",
      "PassengerId: 453, Name: Foreman, Mr. Benjamin Laventall, ìƒì¡´ í™•ë¥ : 0.3383\n",
      "PassengerId: 412, Name: Hart, Mr. Henry, ìƒì¡´ í™•ë¥ : 0.0921\n",
      "PassengerId: 995, Name: Johansson Palmquist, Mr. Oskar Leander, ìƒì¡´ í™•ë¥ : 0.0787\n",
      "PassengerId: 336, Name: Denkoff, Mr. Mitto, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 1216, Name: Kreuchen, Miss. Emilie, ìƒì¡´ í™•ë¥ : 0.9685\n",
      "PassengerId: 542, Name: Andersson, Miss. Ingeborg Constanzia, ìƒì¡´ í™•ë¥ : 0.6592\n",
      "PassengerId: 710, Name: Moubarek, Master. Halim Gonios (\"William George\"), ìƒì¡´ í™•ë¥ : 0.0374\n",
      "PassengerId: 879, Name: Laleff, Mr. Kristo, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 57, Name: Rugg, Miss. Emily, ìƒì¡´ í™•ë¥ : 0.9064\n",
      "PassengerId: 80, Name: Dowdell, Miss. Elizabeth, ìƒì¡´ í™•ë¥ : 0.6997\n",
      "PassengerId: 921, Name: Samaan, Mr. Elias, ìƒì¡´ í™•ë¥ : 0.0365\n",
      "PassengerId: 771, Name: Lievens, Mr. Rene Aime, ìƒì¡´ í™•ë¥ : 0.0844\n",
      "PassengerId: 298, Name: Allison, Miss. Helen Loraine, ìƒì¡´ í™•ë¥ : 0.9835\n",
      "PassengerId: 551, Name: Thayer, Mr. John Borland Jr, ìƒì¡´ í™•ë¥ : 0.4512\n",
      "PassengerId: 154, Name: van Billiard, Mr. Austin Blyler, ìƒì¡´ í™•ë¥ : 0.0382\n",
      "PassengerId: 249, Name: Beckwith, Mr. Richard Leonard, ìƒì¡´ í™•ë¥ : 0.3109\n",
      "PassengerId: 41, Name: Ahlin, Mrs. Johan (Johanna Persdotter Larsson), ìƒì¡´ í™•ë¥ : 0.5739\n",
      "PassengerId: 1180, Name: Mardirosian, Mr. Sarkis, ìƒì¡´ í™•ë¥ : 0.0494\n",
      "PassengerId: 875, Name: Abelson, Mrs. Samuel (Hannah Wizosky), ìƒì¡´ í™•ë¥ : 0.8218\n",
      "PassengerId: 633, Name: Stahelin-Maeglin, Dr. Max, ìƒì¡´ í™•ë¥ : 0.3246\n",
      "PassengerId: 301, Name: Kelly, Miss. Anna Katherine \"Annie Kate\", ìƒì¡´ í™•ë¥ : 0.7591\n",
      "PassengerId: 846, Name: Abbing, Mr. Anthony, ìƒì¡´ í™•ë¥ : 0.0460\n",
      "PassengerId: 791, Name: Keane, Mr. Andrew \"Andy\", ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 106, Name: Mionoff, Mr. Stoytcho, ìƒì¡´ í™•ë¥ : 0.0737\n",
      "PassengerId: 765, Name: Eklund, Mr. Hans Linus, ìƒì¡´ í™•ë¥ : 0.1087\n",
      "PassengerId: 352, Name: Williams-Lambert, Mr. Fletcher Fellows, ìƒì¡´ í™•ë¥ : 0.4293\n",
      "PassengerId: 1093, Name: Danbom, Master. Gilbert Sigvard Emanuel, ìƒì¡´ í™•ë¥ : 0.1425\n",
      "PassengerId: 1135, Name: Hyman, Mr. Abraham, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 56, Name: Woolner, Mr. Hugh, ìƒì¡´ í™•ë¥ : 0.4297\n",
      "PassengerId: 268, Name: Persson, Mr. Ernst Ulrik, ìƒì¡´ í™•ë¥ : 0.0687\n",
      "PassengerId: 1121, Name: Hocking, Mr. Samuel James Metcalfe, ìƒì¡´ í™•ë¥ : 0.1560\n",
      "PassengerId: 816, Name: Fry, Mr. Richard, ìƒì¡´ í™•ë¥ : 0.4003\n",
      "PassengerId: 144, Name: Burke, Mr. Jeremiah, ìƒì¡´ í™•ë¥ : 0.1300\n",
      "PassengerId: 443, Name: Petterson, Mr. Johan Emil, ìƒì¡´ í™•ë¥ : 0.0687\n",
      "PassengerId: 1044, Name: Storey, Mr. Thomas, ìƒì¡´ í™•ë¥ : 0.0265\n",
      "PassengerId: 334, Name: Vander Planke, Mr. Leo Edmondus, ìƒì¡´ í™•ë¥ : 0.0807\n",
      "PassengerId: 502, Name: Canavan, Miss. Mary, ìƒì¡´ í™•ë¥ : 0.8122\n",
      "PassengerId: 652, Name: Doling, Miss. Elsie, ìƒì¡´ í™•ë¥ : 0.9076\n",
      "PassengerId: 413, Name: Minahan, Miss. Daisy E, ìƒì¡´ í™•ë¥ : 0.9663\n",
      "PassengerId: 1046, Name: Asplund, Master. Filip Oscar, ìƒì¡´ í™•ë¥ : 0.0514\n",
      "PassengerId: 998, Name: Buckley, Mr. Daniel, ìƒì¡´ í™•ë¥ : 0.1225\n",
      "PassengerId: 126, Name: Nicola-Yarred, Master. Elias, ìƒì¡´ í™•ë¥ : 0.0766\n",
      "PassengerId: 26, Name: Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson), ìƒì¡´ í™•ë¥ : 0.4415\n",
      "PassengerId: 825, Name: Panula, Master. Urho Abraham, ìƒì¡´ í™•ë¥ : 0.0863\n",
      "PassengerId: 460, Name: O'Connor, Mr. Maurice, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 325, Name: Sage, Mr. George John Jr, ìƒì¡´ í™•ë¥ : 0.0161\n",
      "PassengerId: 213, Name: Perkin, Mr. John Henry, ìƒì¡´ í™•ë¥ : 0.0895\n",
      "PassengerId: 116, Name: Pekoniemi, Mr. Edvard, ìƒì¡´ í™•ë¥ : 0.0926\n",
      "PassengerId: 851, Name: Andersson, Master. Sigvard Harald Elias, ìƒì¡´ í™•ë¥ : 0.0695\n",
      "PassengerId: 1103, Name: Finoli, Mr. Luigi, ìƒì¡´ í™•ë¥ : 0.0690\n",
      "PassengerId: 29, Name: O'Dwyer, Miss. Ellen \"Nellie\", ìƒì¡´ í™•ë¥ : 0.7592\n",
      "PassengerId: 777, Name: Tobin, Mr. Roger, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 548, Name: Padro y Manent, Mr. Julian, ìƒì¡´ í™•ë¥ : 0.1389\n",
      "PassengerId: 715, Name: Greenberg, Mr. Samuel, ìƒì¡´ í™•ë¥ : 0.0946\n",
      "PassengerId: 1120, Name: Everett, Mr. Thomas James, ìƒì¡´ í™•ë¥ : 0.0496\n",
      "PassengerId: 162, Name: Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Milne), ìƒì¡´ í™•ë¥ : 0.8336\n",
      "PassengerId: 750, Name: Connaghton, Mr. Michael, ìƒì¡´ í™•ë¥ : 0.0891\n",
      "PassengerId: 1218, Name: Becker, Miss. Ruth Elizabeth, ìƒì¡´ í™•ë¥ : 0.8993\n",
      "PassengerId: 1071, Name: Compton, Mrs. Alexander Taylor (Mary Eliza Ingersoll), ìƒì¡´ í™•ë¥ : 0.8128\n",
      "PassengerId: 322, Name: Danoff, Mr. Yoto, ìƒì¡´ í™•ë¥ : 0.0761\n",
      "PassengerId: 5, Name: Allen, Mr. William Henry, ìƒì¡´ í™•ë¥ : 0.0584\n",
      "PassengerId: 163, Name: Bengtsson, Mr. John Viktor, ìƒì¡´ í™•ë¥ : 0.0787\n",
      "PassengerId: 534, Name: Peter, Mrs. Catherine (Catherine Rizk), ìƒì¡´ í™•ë¥ : 0.5635\n",
      "PassengerId: 197, Name: Mernagh, Mr. Robert, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 200, Name: Yrois, Miss. Henriette (\"Mrs Harbeck\"), ìƒì¡´ í™•ë¥ : 0.8977\n",
      "PassengerId: 128, Name: Madsen, Mr. Fridtjof Arne, ìƒì¡´ í™•ë¥ : 0.0838\n",
      "PassengerId: 1177, Name: Dennis, Mr. William, ìƒì¡´ í™•ë¥ : 0.0563\n",
      "PassengerId: 8, Name: Palsson, Master. Gosta Leonard, ìƒì¡´ í™•ë¥ : 0.0961\n",
      "PassengerId: 320, Name: Spedden, Mrs. Frederic Oakley (Margaretta Corning Stone), ìƒì¡´ í™•ë¥ : 0.9207\n",
      "PassengerId: 640, Name: Thorneycroft, Mr. Percival, ìƒì¡´ í™•ë¥ : 0.0600\n",
      "PassengerId: 127, Name: McMahon, Mr. Martin, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 100, Name: Kantor, Mr. Sinai, ìƒì¡´ í™•ë¥ : 0.1475\n",
      "PassengerId: 1040, Name: Crafton, Mr. John Bertram, ìƒì¡´ í™•ë¥ : 0.4222\n",
      "PassengerId: 1132, Name: Lindstrom, Mrs. Carl Johan (Sigrid Posse), ìƒì¡´ í™•ë¥ : 0.8666\n",
      "PassengerId: 755, Name: Herman, Mrs. Samuel (Jane Laver), ìƒì¡´ í™•ë¥ : 0.7390\n",
      "PassengerId: 10, Name: Nasser, Mrs. Nicholas (Adele Achem), ìƒì¡´ í™•ë¥ : 0.8857\n",
      "PassengerId: 626, Name: Sutton, Mr. Frederick, ìƒì¡´ í™•ë¥ : 0.1974\n",
      "PassengerId: 757, Name: Carlsson, Mr. August Sigfrid, ìƒì¡´ í™•ë¥ : 0.0737\n",
      "PassengerId: 781, Name: Ayoub, Miss. Banoura, ìƒì¡´ í™•ë¥ : 0.7459\n",
      "PassengerId: 12, Name: Bonnell, Miss. Elizabeth, ìƒì¡´ í™•ë¥ : 0.8926\n",
      "PassengerId: 185, Name: Kink-Heilmann, Miss. Luise Gretchen, ìƒì¡´ í™•ë¥ : 0.8225\n",
      "PassengerId: 245, Name: Attalah, Mr. Sleiman, ìƒì¡´ í™•ë¥ : 0.0492\n",
      "PassengerId: 1281, Name: Palsson, Master. Paul Folke, ìƒì¡´ í™•ë¥ : 0.0844\n",
      "PassengerId: 800, Name: Van Impe, Mrs. Jean Baptiste (Rosalie Paula Govaert), ìƒì¡´ í™•ë¥ : 0.6384\n",
      "PassengerId: 910, Name: Ilmakangas, Miss. Ida Livija, ìƒì¡´ í™•ë¥ : 0.6804\n",
      "PassengerId: 850, Name: Goldenberg, Mrs. Samuel L (Edwiga Grabowska), ìƒì¡´ í™•ë¥ : 0.9423\n",
      "PassengerId: 196, Name: Lurette, Miss. Elise, ìƒì¡´ í™•ë¥ : 0.8975\n",
      "PassengerId: 1203, Name: Vartanian, Mr. David, ìƒì¡´ í™•ë¥ : 0.0643\n",
      "PassengerId: 23, Name: McGowan, Miss. Anna \"Annie\", ìƒì¡´ í™•ë¥ : 0.8428\n",
      "PassengerId: 776, Name: Myhrman, Mr. Pehr Fabian Oliver Malkolm, ìƒì¡´ í™•ë¥ : 0.1020\n",
      "PassengerId: 299, Name: Saalfeld, Mr. Adolphe, ìƒì¡´ í™•ë¥ : 0.4255\n",
      "PassengerId: 342, Name: Fortune, Miss. Alice Elizabeth, ìƒì¡´ í™•ë¥ : 0.9651\n",
      "PassengerId: 975, Name: Demetri, Mr. Marinko, ìƒì¡´ í™•ë¥ : 0.0692\n",
      "PassengerId: 240, Name: Hunt, Mr. George Henry, ìƒì¡´ í™•ë¥ : 0.1702\n",
      "PassengerId: 900, Name: Abrahim, Mrs. Joseph (Sophie Halaut Easu), ìƒì¡´ í™•ë¥ : 0.7106\n",
      "PassengerId: 913, Name: Olsen, Master. Artur Karl, ìƒì¡´ í™•ë¥ : 0.1185\n",
      "PassengerId: 376, Name: Meyer, Mrs. Edgar Joseph (Leila Saks), ìƒì¡´ í™•ë¥ : 0.9410\n",
      "PassengerId: 1181, Name: Ford, Mr. Arthur, ìƒì¡´ í™•ë¥ : 0.0693\n",
      "PassengerId: 963, Name: Minkoff, Mr. Lazar, ìƒì¡´ í™•ë¥ : 0.0926\n",
      "PassengerId: 608, Name: Daniel, Mr. Robert Williams, ìƒì¡´ í™•ë¥ : 0.4508\n",
      "PassengerId: 304, Name: Keane, Miss. Nora A, ìƒì¡´ í™•ë¥ : 0.9067\n",
      "PassengerId: 1158, Name: Chisholm, Mr. Roderick Robert Crispin, ìƒì¡´ í™•ë¥ : 0.4003\n",
      "PassengerId: 244, Name: Maenpaa, Mr. Matti Alexanteri, ìƒì¡´ í™•ë¥ : 0.0895\n",
      "PassengerId: 721, Name: Harper, Miss. Annie Jessie \"Nina\", ìƒì¡´ í™•ë¥ : 0.9397\n",
      "PassengerId: 917, Name: Robins, Mr. Alexander A, ìƒì¡´ í™•ë¥ : 0.0300\n",
      "PassengerId: 1057, Name: Kink-Heilmann, Mrs. Anton (Luise Heilmann), ìƒì¡´ í™•ë¥ : 0.6690\n",
      "PassengerId: 330, Name: Hippach, Miss. Jean Gertrude, ìƒì¡´ í™•ë¥ : 0.9619\n",
      "PassengerId: 221, Name: Sunderland, Mr. Victor Francis, ìƒì¡´ í™•ë¥ : 0.1088\n",
      "PassengerId: 912, Name: Rothschild, Mr. Martin, ìƒì¡´ í™•ë¥ : 0.1631\n",
      "PassengerId: 920, Name: Brady, Mr. John Bertram, ìƒì¡´ í™•ë¥ : 0.3326\n",
      "PassengerId: 72, Name: Goodwin, Miss. Lillian Amy, ìƒì¡´ í™•ë¥ : 0.5700\n",
      "PassengerId: 158, Name: Corn, Mr. Harry, ìƒì¡´ í™•ë¥ : 0.0690\n",
      "PassengerId: 615, Name: Brocklebank, Mr. William Alfred, ìƒì¡´ í™•ë¥ : 0.0584\n",
      "PassengerId: 1232, Name: Fillbrook, Mr. Joseph Charles, ìƒì¡´ í™•ë¥ : 0.2581\n",
      "PassengerId: 1163, Name: Fox, Mr. Patrick, ìƒì¡´ í™•ë¥ : 0.0923\n",
      "PassengerId: 263, Name: Taussig, Mr. Emil, ìƒì¡´ í™•ë¥ : 0.2247\n",
      "PassengerId: 89, Name: Fortune, Miss. Mabel Helen, ìƒì¡´ í™•ë¥ : 0.9662\n",
      "PassengerId: 938, Name: Chevre, Mr. Paul Romaine, ìƒì¡´ í™•ë¥ : 0.2317\n",
      "PassengerId: 746, Name: Crosby, Capt. Edward Gifford, ìƒì¡´ í™•ë¥ : 0.1291\n",
      "PassengerId: 801, Name: Ponesell, Mr. Martin, ìƒì¡´ í™•ë¥ : 0.1656\n",
      "PassengerId: 512, Name: Webber, Mr. James, ìƒì¡´ í™•ë¥ : 0.0693\n",
      "PassengerId: 62, Name: Icard, Miss. Amelie, ìƒì¡´ í™•ë¥ : 0.9531\n",
      "PassengerId: 262, Name: Asplund, Master. Edvin Rojj Felix, ìƒì¡´ í™•ë¥ : 0.0718\n",
      "PassengerId: 210, Name: Blank, Mr. Henry, ìƒì¡´ í™•ë¥ : 0.2658\n",
      "PassengerId: 307, Name: Fleming, Miss. Margaret, ìƒì¡´ í™•ë¥ : 0.9548\n",
      "PassengerId: 1136, Name: Johnston, Master. William Arthur Willie\"\", ìƒì¡´ í™•ë¥ : 0.0475\n",
      "PassengerId: 887, Name: Montvila, Rev. Juozas, ìƒì¡´ í™•ë¥ : 0.2030\n",
      "PassengerId: 371, Name: Harder, Mr. George Achilles, ìƒì¡´ í™•ë¥ : 0.3589\n",
      "PassengerId: 442, Name: Hampe, Mr. Leon, ìƒì¡´ í™•ë¥ : 0.0961\n",
      "PassengerId: 1260, Name: Gibson, Mrs. Leonard (Pauline C Boeson), ìƒì¡´ í™•ë¥ : 0.9002\n",
      "PassengerId: 60, Name: Goodwin, Master. William Frederick, ìƒì¡´ í™•ë¥ : 0.0487\n",
      "PassengerId: 625, Name: Bowen, Mr. David John \"Dai\", ìƒì¡´ í™•ë¥ : 0.0950\n",
      "PassengerId: 1131, Name: Douglas, Mrs. Walter Donald (Mahala Dutton), ìƒì¡´ í™•ë¥ : 0.9009\n",
      "PassengerId: 64, Name: Skoog, Master. Harald, ìƒì¡´ í™•ë¥ : 0.0813\n",
      "PassengerId: 588, Name: Frolicher-Stehli, Mr. Maxmillian, ìƒì¡´ í™•ë¥ : 0.1322\n",
      "PassengerId: 744, Name: McNamee, Mr. Neal, ìƒì¡´ í™•ë¥ : 0.0729\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"titanic1309.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ ì‚¬ìš©í•  ì—´ ì„ íƒ\n",
    "X = df[['PassengerId', 'Name', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "# 3ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: í‰ê· ìœ¼ë¡œ, ë²”ì£¼í˜•: ê°€ì¥ ë§ì€ ê°’ìœ¼ë¡œ)\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ ë²”ì£¼í˜•ì„ ìˆ«ìë¡œ ë³€í™˜ (ì›-í•« ì¸ì½”ë”©)\n",
    "X_model = X.drop(['PassengerId', 'Name'], axis=1)\n",
    "X_model = pd.get_dummies(X_model, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# 5ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_model[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.fit_transform(\n",
    "    X_model[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']]\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸° (PassengerId, Name í¬í•¨í•´ì„œ ê°™ì´ ë‚˜ëˆ„ê¸°)\n",
    "X_train_model, X_test_model, X_train_meta, X_test_meta, y_train, y_test = train_test_split(\n",
    "    X_model, X[['PassengerId', 'Name']], y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 7ï¸âƒ£ TensorFlow ëª¨ë¸\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_model.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_model, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 8ï¸âƒ£ í…ŒìŠ¤íŠ¸ì…‹ ì •í™•ë„ í‰ê°€\n",
    "test_loss, test_acc = model.evaluate(X_test_model, y_test, verbose=0)\n",
    "print(f\"[TensorFlow] Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 9ï¸âƒ£ í…ŒìŠ¤íŠ¸ì…‹ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥  ì¶œë ¥ (PassengerId, Name í¬í•¨)\n",
    "y_pred_probs = model.predict(X_test_model)\n",
    "\n",
    "# 0~1 ì‚¬ì´ì˜ ìƒì¡´ í™•ë¥ ê³¼ PassengerId, Name í•¨ê»˜ ì¶œë ¥\n",
    "print(\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ì…‹ ê° ìƒ˜í”Œë³„ ìƒì¡´ í™•ë¥ :\")\n",
    "for idx in range(len(y_pred_probs)):\n",
    "    passenger_id = X_test_meta.iloc[idx]['PassengerId']\n",
    "    passenger_name = X_test_meta.iloc[idx]['Name']\n",
    "    prob = y_pred_probs[idx][0]\n",
    "    print(f\"PassengerId: {passenger_id}, Name: {passenger_name}, ìƒì¡´ í™•ë¥ : {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28211f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/1830346097.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/opt/miniconda3/envs/VDLP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4847 - loss: 0.8372 - val_accuracy: 0.6333 - val_loss: 0.6874\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6661 - loss: 0.6697 - val_accuracy: 0.7000 - val_loss: 0.5971\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6860 - loss: 0.6256 - val_accuracy: 0.7238 - val_loss: 0.5522\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6842 - loss: 0.5914 - val_accuracy: 0.7571 - val_loss: 0.5193\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7059 - loss: 0.5799 - val_accuracy: 0.7810 - val_loss: 0.4964\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7379 - loss: 0.5249 - val_accuracy: 0.7905 - val_loss: 0.4770\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7515 - loss: 0.5192 - val_accuracy: 0.8095 - val_loss: 0.4605\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7418 - loss: 0.5287 - val_accuracy: 0.8190 - val_loss: 0.4468\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7483 - loss: 0.5250 - val_accuracy: 0.8143 - val_loss: 0.4347\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7876 - loss: 0.4724 - val_accuracy: 0.8429 - val_loss: 0.4231\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7882 - loss: 0.4704 - val_accuracy: 0.8524 - val_loss: 0.4163\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7968 - loss: 0.4542 - val_accuracy: 0.8667 - val_loss: 0.4087\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.4499 - val_accuracy: 0.8762 - val_loss: 0.4056\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8215 - loss: 0.4464 - val_accuracy: 0.8762 - val_loss: 0.3984\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8183 - loss: 0.4501 - val_accuracy: 0.8714 - val_loss: 0.3937\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8238 - loss: 0.4441 - val_accuracy: 0.8714 - val_loss: 0.3904\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8425 - loss: 0.4007 - val_accuracy: 0.8762 - val_loss: 0.3844\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8390 - loss: 0.4219 - val_accuracy: 0.8762 - val_loss: 0.3823\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8273 - loss: 0.4319 - val_accuracy: 0.8714 - val_loss: 0.3798\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8300 - loss: 0.4183 - val_accuracy: 0.8762 - val_loss: 0.3774\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8517 - loss: 0.4090 - val_accuracy: 0.8714 - val_loss: 0.3745\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.4040 - val_accuracy: 0.8714 - val_loss: 0.3735\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8302 - loss: 0.4156 - val_accuracy: 0.8714 - val_loss: 0.3740\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8613 - loss: 0.3889 - val_accuracy: 0.8714 - val_loss: 0.3727\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8393 - loss: 0.4023 - val_accuracy: 0.8714 - val_loss: 0.3722\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8413 - loss: 0.4235 - val_accuracy: 0.8714 - val_loss: 0.3721\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8247 - loss: 0.4014 - val_accuracy: 0.8714 - val_loss: 0.3719\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8447 - loss: 0.4049 - val_accuracy: 0.8714 - val_loss: 0.3704\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8513 - loss: 0.3922 - val_accuracy: 0.8714 - val_loss: 0.3706\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8428 - loss: 0.3982 - val_accuracy: 0.8714 - val_loss: 0.3679\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.4437 - val_accuracy: 0.8714 - val_loss: 0.3695\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8544 - loss: 0.3886 - val_accuracy: 0.8714 - val_loss: 0.3682\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8539 - loss: 0.3983 - val_accuracy: 0.8714 - val_loss: 0.3681\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8433 - loss: 0.4167 - val_accuracy: 0.8762 - val_loss: 0.3670\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8398 - loss: 0.4078 - val_accuracy: 0.8714 - val_loss: 0.3709\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.3627 - val_accuracy: 0.8762 - val_loss: 0.3717\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.3734 - val_accuracy: 0.8810 - val_loss: 0.3718\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8236 - loss: 0.3777 - val_accuracy: 0.8762 - val_loss: 0.3691\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8456 - loss: 0.3879 - val_accuracy: 0.8762 - val_loss: 0.3692\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.3787 - val_accuracy: 0.8762 - val_loss: 0.3701\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8395 - loss: 0.3896 - val_accuracy: 0.8714 - val_loss: 0.3716\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8416 - loss: 0.4007 - val_accuracy: 0.8714 - val_loss: 0.3705\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8652 - loss: 0.3692 - val_accuracy: 0.8714 - val_loss: 0.3743\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8488 - loss: 0.3956 - val_accuracy: 0.8714 - val_loss: 0.3749\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8329 - loss: 0.3988 - val_accuracy: 0.8714 - val_loss: 0.3715\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8280 - loss: 0.4422 - val_accuracy: 0.8714 - val_loss: 0.3713\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8234 - loss: 0.4169 - val_accuracy: 0.8714 - val_loss: 0.3686\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8384 - loss: 0.4030 - val_accuracy: 0.8714 - val_loss: 0.3696\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8466 - loss: 0.3908 - val_accuracy: 0.8762 - val_loss: 0.3706\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8394 - loss: 0.4230 - val_accuracy: 0.8762 - val_loss: 0.3687\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "ğŸ¯ ì „ì²´ ì…ë ¥ ë°ì´í„°ì…‹ ìƒì¡´ í™•ë¥  (ì• 10ê°œ):\n",
      "PassengerId: 1, Name: Braund, Mr. Owen Harris, ìƒì¡´ í™•ë¥ : 0.0790\n",
      "PassengerId: 2, Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), ìƒì¡´ í™•ë¥ : 0.8943\n",
      "PassengerId: 3, Name: Heikkinen, Miss. Laina, ìƒì¡´ í™•ë¥ : 0.7334\n",
      "PassengerId: 4, Name: Futrelle, Mrs. Jacques Heath (Lily May Peel), ìƒì¡´ í™•ë¥ : 0.9330\n",
      "PassengerId: 5, Name: Allen, Mr. William Henry, ìƒì¡´ í™•ë¥ : 0.0602\n",
      "PassengerId: 6, Name: Moran, Mr. James, ìƒì¡´ í™•ë¥ : 0.0827\n",
      "PassengerId: 7, Name: McCarthy, Mr. Timothy J, ìƒì¡´ í™•ë¥ : 0.2107\n",
      "PassengerId: 8, Name: Palsson, Master. Gosta Leonard, ìƒì¡´ í™•ë¥ : 0.1074\n",
      "PassengerId: 9, Name: Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg), ìƒì¡´ í™•ë¥ : 0.6961\n",
      "PassengerId: 10, Name: Nasser, Mrs. Nicholas (Adele Achem), ìƒì¡´ í™•ë¥ : 0.8661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"titanic1309.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ ì‚¬ìš©í•  ì—´ ì„ íƒ\n",
    "X = df[['PassengerId', 'Name', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "# 3ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ ì›-í•« ì¸ì½”ë”© (PassengerId, Name ì œì™¸)\n",
    "X_model = X.drop(['PassengerId', 'Name'], axis=1)\n",
    "X_model = pd.get_dummies(X_model, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# 5ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_model[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.fit_transform(\n",
    "    X_model[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']]\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "X_train_model, X_test_model, X_train_meta, X_test_meta, y_train, y_test = train_test_split(\n",
    "    X_model, X[['PassengerId', 'Name']], y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 7ï¸âƒ£ ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_model.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_model, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 8ï¸âƒ£ ì „ì²´ ì…ë ¥ ë°ì´í„°ì…‹ì˜ ìƒì¡´ í™•ë¥  êµ¬í•˜ê¸°\n",
    "y_pred_probs_all = model.predict(X_model)\n",
    "\n",
    "# 9ï¸âƒ£ ì›ë³¸ ë°ì´í„°ì™€ ìƒì¡´ í™•ë¥  í•©ì¹˜ê¸°\n",
    "df['Survival_Probability'] = y_pred_probs_all\n",
    "\n",
    "# ğŸ”Ÿ ê²°ê³¼ ì¶œë ¥ (ì• 10ê°œë§Œ ì˜ˆì‹œ)\n",
    "print(\"\\nğŸ¯ ì „ì²´ ì…ë ¥ ë°ì´í„°ì…‹ ìƒì¡´ í™•ë¥  (ì• 10ê°œ):\")\n",
    "for idx, row in df.head(10).iterrows():\n",
    "    print(f\"PassengerId: {row['PassengerId']}, Name: {row['Name']}, ìƒì¡´ í™•ë¥ : {row['Survival_Probability']:.4f}\")\n",
    "\n",
    "# 1ï¸âƒ£1ï¸âƒ£ (ì„ íƒ) CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "# df[['PassengerId', 'Name', 'Survival_Probability']].to_csv('titanic_survival_probabilities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ed4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Pclass_Survival_Prob  \\\n",
      "0       3    male  22.0      1      0   7.2500        S              0.271143   \n",
      "1       1  female  38.0      1      0  71.2833        C              0.570291   \n",
      "2       3  female  26.0      0      0   7.9250        S              0.271143   \n",
      "3       1  female  35.0      1      0  53.1000        S              0.570291   \n",
      "4       3    male  35.0      0      0   8.0500        S              0.271143   \n",
      "\n",
      "   Sex_Survival_Prob  Age_Survival_Prob  SibSp_Survival_Prob  \\\n",
      "0           0.133316           0.391650             0.377935   \n",
      "1           0.819024           0.362310             0.377935   \n",
      "2           0.819024           0.384232             0.376837   \n",
      "3           0.819024           0.367741             0.377935   \n",
      "4           0.133316           0.367741             0.376837   \n",
      "\n",
      "   Parch_Survival_Prob  Fare_Survival_Prob  Embarked_Survival_Prob  \n",
      "0             0.353735            0.311966                0.335817  \n",
      "1             0.353735            0.485261                0.489335  \n",
      "2             0.353735            0.313625                0.335817  \n",
      "3             0.353735            0.433686                0.335817  \n",
      "4             0.353735            0.313933                0.335817  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer   # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ìš©\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° â”€ íŒŒì¼ ê²½ë¡œë¥¼ ìì‹ ì˜ CSV ê²½ë¡œë¡œ ë°”ê¿” ì£¼ì„¸ìš”\n",
    "df = pd.read_csv(\"titanic1309.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ íŠ¹ì„± ë¦¬ìŠ¤íŠ¸\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# 3ï¸âƒ£ ë²”ì£¼í˜•ìœ¼ë¡œ ë‹¤ë£° ì—´ ì§€ì •\n",
    "categorical_feats = [\"Pclass\", \"Sex\", \"Embarked\"]   # Pclassë„ ë²”ì£¼ì²˜ëŸ¼ ì·¨ê¸‰\n",
    "\n",
    "def compute_survival_prob(feature: str, data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ featureë§Œ ì‚¬ìš©í•´ ìƒì¡´ í™•ë¥ ì„ ê³„ì‚°í•œ ë’¤,\n",
    "    (í–‰ ìˆ˜,) ëª¨ì–‘ì˜ ì‹œë¦¬ì¦ˆë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "    \"\"\"\n",
    "    X = data[[feature]].copy()\n",
    "    y = data[\"Survived\"]\n",
    "\n",
    "    # â”€â”€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #\n",
    "    if feature in categorical_feats:                          # â–¸ ë²”ì£¼í˜•\n",
    "        preprocessor = ColumnTransformer(\n",
    "            [(\"cat\",\n",
    "              Pipeline([\n",
    "                  (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                  (\"ohe\", OneHotEncoder(drop=\"first\"))\n",
    "              ]),\n",
    "              [feature])],\n",
    "            remainder=\"passthrough\"\n",
    "        )\n",
    "    else:                                                     # â–¸ ìˆ˜ì¹˜í˜•\n",
    "        preprocessor = ColumnTransformer(\n",
    "            [(\"num\",\n",
    "              Pipeline([\n",
    "                  (\"impute\", SimpleImputer(strategy=\"mean\")),\n",
    "                  (\"scale\", StandardScaler())\n",
    "              ]),\n",
    "              [feature])],\n",
    "            remainder=\"passthrough\"\n",
    "        )\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #\n",
    "\n",
    "    model = Pipeline(\n",
    "        [(\"prep\", preprocessor),\n",
    "         (\"clf\", LogisticRegression(max_iter=1000))]\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "    prob = model.predict_proba(X)[:, 1]   # ìƒì¡´ í´ë˜ìŠ¤(1)ì˜ í™•ë¥ \n",
    "    return pd.Series(prob, name=f\"{feature}_Survival_Prob\")\n",
    "\n",
    "# 4ï¸âƒ£ ê° íŠ¹ì„±ë³„ ìƒì¡´ í™•ë¥  ê³„ì‚° & ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "for feat in features:\n",
    "    df[f\"{feat}_Survival_Prob\"] = compute_survival_prob(feat, df)\n",
    "\n",
    "# 5ï¸âƒ£ í™•ì¸\n",
    "print(df[[*features, *[f\"{f}_Survival_Prob\" for f in features]]].head())\n",
    "\n",
    "# 6ï¸âƒ£ í•„ìš”í•˜ë‹¤ë©´ ì €ì¥\n",
    "# df.to_csv(\"titanic_with_featurewise_probs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f97244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/2698093281.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "/var/folders/tk/ct0j8j1d0y1ft37qgdzljbzh0000gn/T/ipykernel_2158/2698093281.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mEmbarked\u001b[39m\u001b[33m'\u001b[39m].fillna(df[\u001b[33m'\u001b[39m\u001b[33mEmbarked\u001b[39m\u001b[33m'\u001b[39m].mode()[\u001b[32m0\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 4ï¸âƒ£ ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m encoder = \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfirst\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m categorical = [\u001b[33m'\u001b[39m\u001b[33mPclass\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSex\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEmbarked\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     21\u001b[39m encoded = encoder.fit_transform(df[categorical])\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('titanic1309.csv')\n",
    "\n",
    "# 2ï¸âƒ£ í•„ìš”í•œ ì—´ ì„ íƒ\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "# 3ï¸âƒ£ ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "categorical = ['Pclass', 'Sex', 'Embarked']\n",
    "encoded = encoder.fit_transform(df[categorical])\n",
    "\n",
    "# ì¸ì½”ë”©ëœ ì—´ ì´ë¦„ ë‹¤ì‹œ ìƒì„±\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical))\n",
    "df = pd.concat([df.drop(columns=categorical), encoded_df], axis=1)\n",
    "\n",
    "# 5ï¸âƒ£ í‘œì¤€í™” (ìŠ¤ì¼€ì¼ë§)\n",
    "scaler = StandardScaler()\n",
    "numerical = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "df[numerical] = scaler.fit_transform(df[numerical])\n",
    "\n",
    "# 6ï¸âƒ£ ê° Featureë³„ë¡œ ê°œë³„ ëª¨ë¸ ìƒì„± & ì˜ˆì¸¡\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# í”¼ì²˜ë³„ ìƒì¡´ í™•ë¥  ì˜ˆì¸¡ ì €ì¥\n",
    "feature_probabilities = {}\n",
    "\n",
    "for feature in X.columns:\n",
    "    # ê°œë³„ Featureë§Œ ì‚¬ìš©\n",
    "    X_feature = X[[feature]]\n",
    "    \n",
    "    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # ìƒì¡´ í™•ë¥  (1ì˜ í™•ë¥ )\n",
    "    \n",
    "    # í‰ê·  ìƒì¡´ í™•ë¥  ê³„ì‚°\n",
    "    mean_prob = y_prob.mean()\n",
    "    feature_probabilities[feature] = mean_prob\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ” ê° Featureë³„ í‰ê·  ìƒì¡´ í™•ë¥ :\")\n",
    "for feature, prob in feature_probabilities.items():\n",
    "    print(f\"{feature}: {prob:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
